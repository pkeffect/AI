# README
![alt text](https://github.com/pkeffect/AI/blob/main/images/llm.app.learning.curve.small.png "llm app learning curve")
* The docker-compose.yaml listed above assumes the following:
  *  [Ollama](https://ollama.com/) is installed locally, not in docker.
  * Volumes are stored locally, not in docker.
* This is the most efficient setup for my system.
  * Windows 11 | [Docker Desktop](https://www.docker.com/products/docker-desktop/) | [WSL2](https://learn.microsoft.com/en-us/windows/wsl/install) - [24.10 (Oracular Oriole)](https://ubuntu.com/)
  * AMD Ryzen 9 3900XT | 128GB DDR4 RAM | ASUS TUF RTX 3080 GAMING OC 10GB

Check the docker-compose.yaml for links and information on services also.
  
## Ollama
* [Ollama](https://ollama.com/)
* [Ollama github](https://github.com/ollama/ollama)
* [Ollama Models](https://ollama.com/library?sort=newest)
## OpenWebUI 
* [Open-WebUI](https://openwebui.com/)
* [Open-WebUI github](https://github.com/open-webui/open-webui)
* [Open-WebUI Documentation](https://docs.openwebui.com/)
* [Open-WebUI Pipelines](https://github.com/open-webui/pipelines)
* [Open-WebUI Discord](https://discord.gg/open-webui-1170866489302188073)
## Huggingface
* [Huggingface](https://huggingface.co/)
