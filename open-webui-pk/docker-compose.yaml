# Ollama (not bundled in this setup) | https://ollama.com/
# Open-WebUI:dev-cuda (the heart)| https://github.com/open-webui/open-webui/ | https://docs.openwebui.com/
# Searxng (local secure search)| https://github.com/searxng/searxng/
# Pipelines (owui modding/scaling)| https://github.com/open-webui/pipelines/ | https://docs.openwebui.com/pipelines/
# Tika (RAG) | https://tika.apache.org/
# OpenedAI-Speech (text-to-speech)| https://github.com/matatonic/openedai-speech

services:
#  ollama:
#    volumes:
#      - H:/ai/.ollama:/root/.ollama
#    container_name: ollama
#    pull_policy: always
#    tty: true
#    restart: unless-stopped
#    image: ollama/ollama:latest
#### GPU support
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: 1
#              capabilities:
#                - gpu
#    networks:
#      - "hyperspace"
      
  open-webui-dev-cuda:
    image: ghcr.io/open-webui/open-webui:dev-cuda
    container_name: open-webui-dev-cuda
    stdin_open: true
    tty: true    
    ports:
      - "3000:8080"
    volumes:
      - ./.data-open-webui:/app/backend/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities:
                - gpu      
    extra_hosts:
      - "host.docker.internal:host-gateway"     
    environment:
      - 'SCARF_NO_ANALYTICS=${SCARF_NO_ANALYTICS}'
      - 'DO_NOT_TRACK=${DO_NOT_TRACK}'
      - 'ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY}'
      - 'OLLAMA_BASE_URL=${OLLAMA_BASE_URL}'
      - 'WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}'
      - 'USE_CUDA_DOCKER=${USE_CUDA_DOCKER}'
      - 'COMFYUI_BASE_URL=${COMFYUI_BASE_URL}'
      - 'AUTOMATIC1111_BASE_URL=${AUTOMATIC1111_BASE_URL}'
      - 'TEXT_EXTRACTION_ENGINE=${TEXT_EXTRACTION_ENGINE}'
      - 'ENV=${ENV}'
      - 'USER_AGENT=${USER_AGENT}'
      - 'WEBUI_URL=${WEBUI_URL}'
      - 'GLOBAL_LOG_LEVEL=${GLOBAL_LOG_LEVEL}'
    restart: always
    networks:
      - "hyperspace"

  tika:
    image: apache/tika:latest-full
    container_name: open-webui-tika
    expose:
      - "9998:9998"
    depends_on:
      - open-webui-dev-cuda       
    networks:
      - "hyperspace"
    restart: unless-stopped
    
  searxng:
    image: searxng/searxng:latest
    container_name: open-webui-searxng
    ports:
      - "4000:8080"      
    volumes:
      - ./.data-searxng:/etc/searxng:rw
    depends_on:
      - open-webui-dev-cuda       
    restart: always  
    networks:
      - "hyperspace"
      
  pipelines:
    image: ghcr.io/open-webui/pipelines:main 
    container_name: open-webui-pipelines
    ports:
      - "9099:9099"
    environment:
      - 'RESET_PIPELINES_DIR=${RESET_PIPELINES_DIR}'
#     - 'PIPELINES_REQUIREMENTS_PATH=${PIPELINES_REQUIREMENTS_PATH}'
      - 'PIPELINES_URLS=${PIPELINES_URLS}'
#     - 'ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}'
#     - 'COHERE_API_KEY=${COHERE_API_KEY}'
#     - 'GOOGLE_API_KEY=${GOOGLE_API_KEY}'
    volumes:
      - ./.data-pipelines:/app/pipelines
    depends_on:
      - open-webui-dev-cuda    
    restart: always
    networks:
      - "hyperspace"

  openedai-speech:
    image: ghcr.io/matatonic/openedai-speech:latest
    container_name: open-webui-openedai-speech
    ports:
      - "8000:8000"
    volumes:
      - ./.data-openedai-speech/voices:/app/voices
      - ./.data-openedai-speech/config:/app/config
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities:
                - gpu
    env_file:
      - .env
    depends_on:
      - open-webui-dev-cuda
    networks:
      - "hyperspace"
  
networks:
  hyperspace:
    external: true
